{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generativity and Adversarial Gradients\n",
    "\n",
    "**Purpose:** Quick check to assert that the adversiarial gradients point to the same object (and not just a copy of weights). \n",
    "\n",
    "note: git commit `f241a9c` , if there is an error and it is fixed, this notebook will not run appropriately\n",
    "\n",
    "**Result:** Matrices do not refer to the same object. I believe the transpose operation is copying a new object. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "from typing import List\n",
    "\n",
    "import copy\n",
    "import os\n",
    "import pathlib\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as T\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using device = 'cuda'\n"
     ]
    }
   ],
   "source": [
    "# In case you are fortunate enough to have access to a GPU...\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f\"using {device = }\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def draw(X, img_size: (28,28)):\n",
    "    def draw_single(x): \n",
    "        with torch.no_grad():\n",
    "            plt.imshow(x.detach().cpu().numpy().reshape(img_size), cmap='gray');\n",
    "            plt.axis('off');\n",
    "\n",
    "    if len(X.shape)==4 or len(X.shape)==2:  # display a batch\n",
    "        N = X.shape[0]\n",
    "        plt.figure(figsize=(15,3))\n",
    "        for k,xx in enumerate(X):\n",
    "            plt.subplot(1,10,k+1)\n",
    "            draw_single(xx)\n",
    "    else:\n",
    "        draw_single(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Data: MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./files/MNIST\\raw\\train-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 503: Service Unavailable\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to ./files/MNIST\\raw\\train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf0c07bb703d43fc844ac2631fd7c870",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9912422 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./files/MNIST\\raw\\train-images-idx3-ubyte.gz to ./files/MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 503: Service Unavailable\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to ./files/MNIST\\raw\\train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fddc2f86056a4087acb1527beeaa5bd7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/28881 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./files/MNIST\\raw\\train-labels-idx1-ubyte.gz to ./files/MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 503: Service Unavailable\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to ./files/MNIST\\raw\\t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8445b206d2f542ae94bd49820ada74a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1648877 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./files/MNIST\\raw\\t10k-images-idx3-ubyte.gz to ./files/MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 503: Service Unavailable\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to ./files/MNIST\\raw\\t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c08980cbd96f460281a70783327c947a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4542 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./files/MNIST\\raw\\t10k-labels-idx1-ubyte.gz to ./files/MNIST\\raw\n",
      "\n",
      "Processing...\n",
      "Done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bcech\\anaconda3\\envs\\adv\\lib\\site-packages\\torchvision\\datasets\\mnist.py:502: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  ..\\torch\\csrc\\utils\\tensor_numpy.cpp:143.)\n",
      "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
     ]
    }
   ],
   "source": [
    "# You can change img_size to 14 if you want to use smaller (14x14) images.\n",
    "img_size = 28\n",
    "ds_full = torchvision.datasets.MNIST('./files/', train=True, download=True,\n",
    "                                transform=T.Compose([\n",
    "                                T.Resize((img_size,img_size)),\n",
    "                                T.ToTensor(),\n",
    "                                T.Lambda((lambda x: torch.flatten(x))),\n",
    "                            ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# You can change img_size to 14 if you want to use smaller (14x14) images.\n",
    "img_size = 28\n",
    "ds_test = torchvision.datasets.MNIST('./files/', train=False, download=True,\n",
    "                                transform=T.Compose([\n",
    "                                T.Resize((img_size,img_size)),\n",
    "                                T.ToTensor(),\n",
    "                                T.Lambda((lambda x: torch.flatten(x))),\n",
    "                            ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#ds = ds_full\n",
    "n = 1024*2\n",
    "n_samples = n if n <= len(ds_full) else len(ds_full)\n",
    "\n",
    "ds = torch.utils.data.Subset(ds_full, range(n_samples))\n",
    "dl = torch.utils.data.DataLoader(ds, batch_size=32, shuffle=True)\n",
    "dl_test = torch.utils.data.DataLoader(ds_test, batch_size=256)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyNet(nn.Module):\n",
    "    '''\n",
    "     net = MyNet(img_size=28)\n",
    "     \n",
    "     Creates a neural network to do classification on MNIST.\n",
    "     It assumes the images will be (img_size)x(img_size).\n",
    "     \n",
    "     It projects to a latent space.\n",
    "     From that latent space, it:\n",
    "      1) projects to an output classification layer (log softmax), and\n",
    "      2) projects back down through the network to a reconstruction of the input.\n",
    "     \n",
    "    '''\n",
    "    def __init__(self, img_size=28, latent_dim=5):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Discriminative network\n",
    "        self.D = nn.ModuleList()\n",
    "        \n",
    "        # Input -> Hidden 1\n",
    "        self.D.append(nn.Linear(img_size**2, 100))\n",
    "        self.D.append(nn.ReLU())\n",
    "        \n",
    "        # Hidden 1 -> Hidden 2\n",
    "        self.D.append(nn.Linear(100, latent_dim))\n",
    "        self.D.append(nn.ReLU())\n",
    "        \n",
    "        # Classifier\n",
    "        self.classifier = nn.Sequential(\n",
    "                            nn.Linear(latent_dim, 10),\n",
    "                            nn.LogSoftmax(dim=-1),\n",
    "                            )\n",
    "\n",
    "        # The generative network\n",
    "        self.G = nn.ModuleList()\n",
    "        \n",
    "        # Hidden 2 -> Hidden 1\n",
    "        self.G.append(nn.Linear(latent_dim, 100))\n",
    "        self.G.append(nn.ReLU())\n",
    "        \n",
    "        # Hidden 1 -> Input\n",
    "        self.G.append(nn.Linear(100, img_size**2))\n",
    "        self.G.append(nn.Sigmoid())\n",
    "        \n",
    "        # Tie the weights of D and G\n",
    "        #TODO check if pointer or copy\n",
    "        # check pytorch source to see transpose\n",
    "        # https://pytorch.org/docs/stable/generated/torch.transpose.html#torch.transpose\n",
    "        # ^ shares underlying data, so will not return new object\n",
    "        self.G[-2].weight.data = self.D[0].weight.data.transpose(1,0)\n",
    "        self.G[-4].weight.data = self.D[2].weight.data.transpose(1,0)\n",
    "        self.G[-4].bias.data = self.D[0].bias.data\n",
    "        \n",
    "        self.classifier_loss = nn.NLLLoss()\n",
    "        self.recon_loss = nn.BCELoss()\n",
    "        self.losses = []\n",
    "        self.to(device)\n",
    "        \n",
    "        # checkpoint states\n",
    "        self.optimizer = None\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        '''Latent -> Classification'''\n",
    "        return self.classifier(self.discriminate(x))\n",
    "\n",
    "    \n",
    "    def ae(self,x):\n",
    "        return self.generate(self.discriminate(x))\n",
    "\n",
    "    \n",
    "    def discriminate(self, x):\n",
    "        '''Input -> Latent'''\n",
    "        for d in self.D:\n",
    "            x = d(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "    def generate(self, z):\n",
    "        '''\n",
    "         Latent -> Input\n",
    "         x_had = net.generate(z)\n",
    "         \n",
    "         Runs the network in reverse, generating a batch of inputs from\n",
    "         a batch of latent vectors.\n",
    "         \n",
    "         Inputs:\n",
    "          z      (D,latent_dim) tensor of latent vectors\n",
    "          \n",
    "         Outputs:\n",
    "          x_hat  (D,784) tensor containing the batch of inputs\n",
    "        '''\n",
    "        for g in self.G:\n",
    "            z = g(z)\n",
    "        return z\n",
    "    \n",
    "      \n",
    "    def learn(self, \n",
    "              dl, \n",
    "              optimizer=None, \n",
    "              epochs=10, \n",
    "              beta=0.,\n",
    "              checkpoints=[],\n",
    "              path: str=None,\n",
    "              plot_loss=True):\n",
    "        '''\n",
    "         net.learn(dl, optimizer=None, epochs=10, beta=0.)\n",
    "         \n",
    "         Train the network on the dataset represented by the DataLoader dl.\n",
    "         The default optimizer is Adam().\n",
    "         \n",
    "         The targets for the dataset are assumed to be class indices.\n",
    "         \n",
    "         beta is the weight for the reconstruction loss.\n",
    "         \n",
    "         Args:\n",
    "             dl (Dataloader): \n",
    "             checkpoints (Boolean|List[int]): if True, save every 10-epochs. if List[int], save each listed epoch.\n",
    "             path (str): optional path to save model checkpoints.\n",
    "        '''\n",
    "        if optimizer is None:\n",
    "            print('Need to specify an optimizer')\n",
    "            return\n",
    "        else:\n",
    "            self.optimizer = optimizer\n",
    "        \n",
    "        for epoch in tqdm(range(epochs)):\n",
    "            total_loss = 0.\n",
    "            count = 0.\n",
    "            for x, t in dl:\n",
    "                x = x.to(device)   # for use with a GPU\n",
    "                t = t.to(device)\n",
    "                z = self.discriminate(x)\n",
    "                y = self.classifier(z)\n",
    "                xhat = self.generate(z)\n",
    "                loss = self.classifier_loss(y, t) + beta*self.recon_loss(xhat, x)\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                # set generator weights to equal discirminator weights\n",
    "                # hack fix\n",
    "                #self.G[0].weight.data = self.D[2].weight.data.transpose(1,0)\n",
    "                #self.G[-2].weight.data = self.D[0].weight.data.transpose(1,0)\n",
    "                self.G[-2].weight = torch.nn.Parameter(self.D[0].weight.transpose(1,0))\n",
    "                self.G[-4].weight = torch.nn.Parameter(self.D[2].weight.transpose(1,0))\n",
    "                # delete above hack\n",
    "                total_loss += loss.item()*len(t)\n",
    "                count += 1.\n",
    "            self.losses.append(total_loss/len(dl.dataset))\n",
    "            #print(f'Epoch: {epoch}, loss: {total_loss/count}')\n",
    "            if checkpoints:\n",
    "                self.checkpoint(epoch, checkpoints, path)\n",
    "        \n",
    "        if plot_loss:        \n",
    "            plt.figure(figsize=(4,4))\n",
    "            plt.plot(self.losses); plt.yscale('log');\n",
    "\n",
    "\n",
    "    def checkpoint(self, \n",
    "                   epoch: int, \n",
    "                   checkpoints: List[int]=[],\n",
    "                   path: str=\"model-checkpoints.pt\"):\n",
    "        \"\"\" Save model checkpoints. \n",
    "        \n",
    "            Args:\n",
    "                epoch (int): Current training epoch.\n",
    "                checkpoints (List[int]): list of epochs to save model at. if True, save every 10.model \n",
    "                path (str): path to save model.pt\n",
    "                \n",
    "        \"\"\"\n",
    "        \n",
    "        def save_checkpoint(self, epoch, path):\n",
    "            path = path.split(\".pt\")[0] + f\"-{epoch}\" + \".pt\"\n",
    "            torch.save({'epoch': epoch,\n",
    "                        'model_state_dict': self.state_dict(),\n",
    "                        'optimizer_state_dict': self.optimizer.state_dict(),\n",
    "                        'loss': self.losses[-1],\n",
    "                        }, \n",
    "                        path) \n",
    "        \n",
    "        if checkpoints is True:\n",
    "            if epoch % 10 == 0: \n",
    "                save_checkpoint(self, epoch, path)\n",
    "        elif epoch in checkpoints:\n",
    "            save_checkpoint(self, epoch, path)     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assert Objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = MyNet(28, latent_dim=8)#.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below: The tensors start out with identical weight values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#         self.G[-2].weight.data = self.D[0].weight.data.transpose(1,0)\n",
    "#         self.G[-4].weight.data = self.D[2].weight.data.transpose(1,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert torch.equal(net.G[-2].weight.data.T, net.D[0].weight.data)\n",
    "assert torch.equal(net.G[-4].weight.data.T, net.D[2].weight.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert torch.equal(net.G[0].weight.data.T, net.D[2].weight.data)\n",
    "assert torch.equal(net.G[-2].weight.data.T, net.D[2].weight.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below: but the pointers do not reference the same object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-113-c2b90cc2091d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32massert\u001b[0m \u001b[0mnet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mG\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mnet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mD\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32massert\u001b[0m \u001b[0mnet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mG\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mnet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mD\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32massert\u001b[0m \u001b[0mnet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mG\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mnet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mD\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "assert net.G[-2].weight.data is net.D[0].weight.data.transpose(1,0)\n",
    "assert net.G[-4].weight.data is net.D[2].weight.data.transpose(1,0)\n",
    "assert net.G[-4].bias.data is net.D[0].bias.data.transpose(1,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-116-9b97fd35e612>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32massert\u001b[0m \u001b[0mnet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mG\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mnet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mD\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32massert\u001b[0m \u001b[0mnet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mG\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mnet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mD\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32massert\u001b[0m \u001b[0mnet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mG\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mnet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mD\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "assert net.G[-2] is net.D[0]\n",
    "assert net.G[-4] is net.D[2]\n",
    "assert net.G[-4] is net.D[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-201-39b9d558776f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32massert\u001b[0m \u001b[0mnet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mG\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mnet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mD\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32massert\u001b[0m \u001b[0mnet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mG\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mnet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mD\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32massert\u001b[0m \u001b[0mnet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mG\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mnet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mD\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "assert net.G[-2].weight.data is net.D[0].weight.data.transpose(1,0)\n",
    "assert net.G[-4].weight is net.D[2].weight\n",
    "assert net.G[-4].bias is net.D[0].bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like these asserts will fail, not because the pointers aren't to the same object, but because the transpose operation breaks the `is` comparison. \n",
    "\n",
    "So, have to just test if updates to one affect the other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO check if pointer or copy\n",
    "#self.G[-2].weight.data = self.D[0].weight.data.transpose(1,0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider the zero-th row of `net.G[-2]` and the zero-th column of `net.D[0]` should be equivalent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below: on update of generator, discriminator weights shouldn't change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.G[-2].weight.data[0:1,] = 1\n",
    "\n",
    "assert not net.G[-2].weight.data is net.D[0].weight.data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below: but on update of discriminator, generator _should_ update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-142-a9c49e0dfcfe>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mnet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mD\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m9\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32massert\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mequal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mD\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mG\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "net.D[0].weight.data[0:1,] = 9\n",
    "\n",
    "assert torch.equal(net.D[0].weight.data[0:1,], net.G[-2].weight.data.transpose(1,0)[0:1,])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below: but forcing a chage to `net.G` does update."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.G[-2].weight.data[:,0] = 9\n",
    "\n",
    "assert torch.equal(net.D[0].weight.data[0:1,], net.G[-2].weight.data.transpose(1,0)[0:1,])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Net and Assert Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:05<00:00,  1.14s/it]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "img_size = 28\n",
    "net = MyNet(img_size, latent_dim=8)#.to(device)\n",
    "\n",
    "g_init = net.G[-2].weight.data\n",
    "d_init = net.D[0].weight.data\n",
    "\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=0.001)\n",
    "checkpoints = False\n",
    "#path = f\"data/mnist-{len(dl)}-checkpoint.pt\"\n",
    "\n",
    "net.learn(dl, \n",
    "          optimizer=optimizer, \n",
    "          epochs=5, \n",
    "          beta=3., \n",
    "          checkpoints=checkpoints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#.G[-2].weight.data = self.D[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-250-107cd71e203a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32massert\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mequal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mG\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mD\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32massert\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mequal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mG\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mD\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "assert torch.equal(net.G[-2].weight.data.T, net.D[0].weight.data)\n",
    "assert torch.equal(net.G[-4].weight.data.T, net.D[2].weight.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again: `net.D` gradient indices are `0->2` (and bias at `0`).   while `net.G` gradients, are the reverse `-4 -> -2`.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for i=-2, j=0\n",
      "for i=-4, j=2\n"
     ]
    }
   ],
   "source": [
    "d = [0, 2]\n",
    "g = [-2,-4]\n",
    "\n",
    "\n",
    "for i,j in zip(g,d):\n",
    "    print(f\"for {i=}, {j=}\")\n",
    "    assert torch.equal(net.G[i].weight.data, net.D[j].weight.data.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.1015, -0.0661, -0.0799, -0.0959, -0.0570],\n",
       "        [-0.0944, -0.0668, -0.0944, -0.0583, -0.0533],\n",
       "        [-0.1062, -0.0993, -0.0823, -0.0813, -0.1034],\n",
       "        [-0.0418, -0.1196, -0.0709, -0.0585, -0.0916],\n",
       "        [-0.0591, -0.0511, -0.0514, -0.0741, -0.0876]], device='cuda:0')"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.G[-2].weight.data[:5,:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.1015, -0.0944, -0.1062, -0.0418, -0.0591],\n",
       "        [-0.0661, -0.0668, -0.0993, -0.1196, -0.0511],\n",
       "        [-0.0799, -0.0944, -0.0823, -0.0709, -0.0514],\n",
       "        [-0.0959, -0.0583, -0.0813, -0.0585, -0.0741],\n",
       "        [-0.0570, -0.0533, -0.1034, -0.0916, -0.0876]], device='cuda:0')"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.D[0].weight.data[:5,:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-62-c2ca950c601e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32massert\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mequal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mg_init\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mG\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "assert not torch.equal(g_init, net.G[-2].weight.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-63-525d96ece44b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32massert\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mequal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0md_init\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mD\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "assert not torch.equal(d_init, net.D[0].weight.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check object IDs\n",
    "\n",
    "and maybe memory location"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "note: ID is of the pointer, not the object, it seems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2905600556160"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id(net.G[-2].weight.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2905600495424"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id(net.D[0].weight.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 100])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.G[-2].weight.data[0:1,].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 100])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.D[0].weight.data[:,0:1].T.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check Training Checkpoints\n",
    "\n",
    "Does generator update through training?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 50/50 [00:52<00:00,  1.04s/it]\n"
     ]
    }
   ],
   "source": [
    "img_size = 28\n",
    "net = MyNet(img_size, latent_dim=8)#.to(device)\n",
    "\n",
    "g_init = net.G[-2].weight.data\n",
    "d_init = net.D[0].weight.data\n",
    "assert torch.equal(d_init, g_init.transpose(1,0))\n",
    "\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=0.001)\n",
    "checkpoints = [0,1,5,10,20,49]\n",
    "path = f\"../data/06_models/debug/mnist-train-{len(ds)}-checkpoint.pt\"\n",
    "\n",
    "net.learn(dl, \n",
    "          optimizer=optimizer, \n",
    "          epochs=50, \n",
    "          beta=3., \n",
    "          checkpoints=checkpoints,\n",
    "          path=path,\n",
    "          plot_loss=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "plotting epochs: tensor([[-0.0574, -0.0941,  0.0096, -0.0116, -0.0820],\n",
      "        [-0.0474, -0.0366,  0.0263,  0.0027, -0.0407],\n",
      "        [-0.0489, -0.0431,  0.0134,  0.0253, -0.0301],\n",
      "        [-0.0734, -0.0308, -0.0329,  0.0169, -0.0913],\n",
      "        [-0.0394, -0.0712, -0.0319, -0.0186, -0.0887]], device='cuda:0')\n",
      "tensor([[-0.0734, -0.1089,  0.0096, -0.0116, -0.0936],\n",
      "        [-0.0637, -0.0518,  0.0263,  0.0027, -0.0527],\n",
      "        [-0.0653, -0.0583,  0.0134,  0.0253, -0.0421],\n",
      "        [-0.0896, -0.0459, -0.0329,  0.0169, -0.1032],\n",
      "        [-0.0555, -0.0862, -0.0319, -0.0186, -0.1006]], device='cuda:0')\n",
      "tensor([[-0.0805, -0.1144,  0.0096, -0.0116, -0.0981],\n",
      "        [-0.0711, -0.0576,  0.0263,  0.0027, -0.0573],\n",
      "        [-0.0726, -0.0643,  0.0134,  0.0253, -0.0467],\n",
      "        [-0.0968, -0.0517, -0.0329,  0.0169, -0.1078],\n",
      "        [-0.0629, -0.0919, -0.0319, -0.0186, -0.1052]], device='cuda:0')\n",
      "tensor([[-0.0845, -0.1172,  0.0096, -0.0116, -0.1017],\n",
      "        [-0.0753, -0.0605,  0.0263,  0.0027, -0.0609],\n",
      "        [-0.0765, -0.0673,  0.0134,  0.0253, -0.0502],\n",
      "        [-0.1008, -0.0546, -0.0329,  0.0169, -0.1115],\n",
      "        [-0.0671, -0.0947, -0.0319, -0.0186, -0.1089]], device='cuda:0')\n",
      "tensor([[-0.0863, -0.1187,  0.0096, -0.0116, -0.1076],\n",
      "        [-0.0772, -0.0619,  0.0263,  0.0027, -0.0662],\n",
      "        [-0.0783, -0.0689,  0.0134,  0.0253, -0.0556],\n",
      "        [-0.1026, -0.0562, -0.0329,  0.0169, -0.1173],\n",
      "        [-0.0689, -0.0961, -0.0319, -0.0186, -0.1142]], device='cuda:0')\n",
      "tensor([[-0.0786, -0.1131,  0.0096, -0.0116, -0.0969],\n",
      "        [-0.0691, -0.0561,  0.0263,  0.0027, -0.0560],\n",
      "        [-0.0706, -0.0627,  0.0134,  0.0253, -0.0455],\n",
      "        [-0.0948, -0.0502, -0.0329,  0.0169, -0.1065],\n",
      "        [-0.0609, -0.0904, -0.0319, -0.0186, -0.1039]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "paths = [filepath.absolute() for filepath in pathlib.Path(\"../data/06_models/debug\").glob(\"*.pt\")]\n",
    "model = copy.deepcopy(net)    # just in case, don't mess with net obj\n",
    "\n",
    "# history of net.G[-2]\n",
    "g_history = []\n",
    "d_history = []\n",
    "print(\"plotting epochs:\", end=\" \")\n",
    "for path in paths:\n",
    "    \n",
    "    # load model checkpoint\n",
    "    checkpoint = torch.load(path)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    epoch = checkpoint['epoch']\n",
    "    model.eval()\n",
    "\n",
    "    g_checkpoint = model.G[-2].weight.data\n",
    "    d_checkpoint = model.D[0].weight.data\n",
    "    \n",
    "    g_history.append(g_checkpoint)\n",
    "    d_history.append(d_checkpoint)\n",
    "    \n",
    "    # draw grad subplot line\n",
    "    #print(f\"{epoch}\", end=\", \")\n",
    "    #draw(torch.sign(x.grad[:10]))\n",
    "    \n",
    "    #draw(g_checkpoint, img_size=(784,100))\n",
    "    \n",
    "    print(g_checkpoint[:5,:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-211-a7b06ec5ceb3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32massert\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mequal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0md_init\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mg_init\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# passes on network instantiation above\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "assert torch.equal(d_init, g_init.transpose(1,0)) # passes on network instantiation above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "above: since `d_init` and `g_init` are pointers to the network's respective tensors, the assert passing on instantiation, but failing after training (again) indicates that the two matrices diverge throughout training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i = 0\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-207-01603de1e8ad>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0md_history\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"{i = }\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[1;32massert\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mequal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0md_history\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mg_history\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in range(len(d_history)):\n",
    "    print(f\"{i = }\")\n",
    "    assert torch.equal(d_history[i], g_history[i].transpose(1,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check again with higher gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "plotting epochs: torch.Size([100, 8])\n",
      "tensor([[ 0.0415,  0.0580,  0.0540,  0.0311,  0.1034],\n",
      "        [ 0.0508, -0.0376, -0.0172,  0.0172,  0.0869],\n",
      "        [ 0.0680,  0.0222,  0.0593,  0.0096, -0.0155],\n",
      "        [-0.0193,  0.0904,  0.0055,  0.0258,  0.0173],\n",
      "        [ 0.0626,  0.0281,  0.0178, -0.0091,  0.0475]], device='cuda:0')\n",
      "torch.Size([100, 8])\n",
      "tensor([[ 0.0428,  0.0485,  0.0613,  0.0073,  0.1034],\n",
      "        [ 0.0530, -0.0605, -0.0155,  0.0026,  0.0849],\n",
      "        [ 0.0720, -0.0166,  0.0584, -0.0105, -0.0232],\n",
      "        [-0.0228,  0.0830, -0.0095,  0.0110,  0.0183],\n",
      "        [ 0.0667,  0.0209, -0.0181, -0.0191,  0.0474]], device='cuda:0')\n",
      "torch.Size([100, 8])\n",
      "tensor([[ 0.0312,  0.0788, -0.0034, -0.0635,  0.1462],\n",
      "        [ 0.0690, -0.1749, -0.0151, -0.0057,  0.1857],\n",
      "        [ 0.0468, -0.0423,  0.0839, -0.0662, -0.0208],\n",
      "        [-0.0431,  0.2251, -0.2423, -0.0761, -0.0344],\n",
      "        [ 0.0628,  0.0977, -0.1439, -0.0560,  0.0781]], device='cuda:0')\n",
      "torch.Size([100, 8])\n",
      "tensor([[ 0.0539,  0.0853, -0.0197, -0.0778,  0.1962],\n",
      "        [ 0.1279, -0.2429, -0.0452, -0.0188,  0.2050],\n",
      "        [ 0.0239,  0.0266,  0.0993, -0.0738, -0.0173],\n",
      "        [-0.0505,  0.2484, -0.3392, -0.0806,  0.0143],\n",
      "        [ 0.1160,  0.1982, -0.2571, -0.0426,  0.1358]], device='cuda:0')\n",
      "torch.Size([100, 8])\n",
      "tensor([[ 0.0960,  0.1002, -0.0344, -0.0827,  0.2188],\n",
      "        [ 0.1804, -0.2493, -0.0294, -0.0122,  0.1785],\n",
      "        [ 0.0086,  0.0732,  0.0663, -0.0774, -0.0256],\n",
      "        [-0.0738,  0.2913, -0.3815, -0.0504,  0.0346],\n",
      "        [ 0.0990,  0.2808, -0.4234, -0.0594,  0.2630]], device='cuda:0')\n",
      "torch.Size([100, 8])\n",
      "tensor([[ 0.0447,  0.0967, -0.0119, -0.0401,  0.1127],\n",
      "        [ 0.0521, -0.1185,  0.0335, -0.0008,  0.1274],\n",
      "        [ 0.0536, -0.0830,  0.0684, -0.0523, -0.0182],\n",
      "        [-0.0257,  0.1543, -0.1564, -0.0608, -0.0178],\n",
      "        [ 0.0527,  0.0534, -0.1065, -0.0452,  0.0575]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "paths = [filepath.absolute() for filepath in pathlib.Path(\"../data/06_models/debug\").glob(\"*.pt\")]\n",
    "model = copy.deepcopy(net)    # just in case, don't mess with net obj\n",
    "\n",
    "# history of net.G[-4]\n",
    "g_history = []\n",
    "d_history= []\n",
    "\n",
    "print(\"plotting epochs:\", end=\" \")\n",
    "for path in paths:\n",
    "    \n",
    "    # load model checkpoint\n",
    "    checkpoint = torch.load(path)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    epoch = checkpoint['epoch']\n",
    "    model.eval()\n",
    "\n",
    "    g_checkpoint = model.G[-4].weight.data\n",
    "    d_checkpint = model.D[0].weight.data\n",
    "    \n",
    "    # draw grad subplot line\n",
    "    #print(f\"{epoch}\", end=\", \")\n",
    "    #draw(torch.sign(x.grad[:10]))\n",
    "    \n",
    "    #draw(g_checkpoint, img_size=(100,8))\n",
    "    print(g_checkpoint[:5,:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Check on Arbitrary Tensors\n",
    "\n",
    "**Shows**: that referencing a torch tensor pointer can work, update, and not create a copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "a = torch.rand((2,4))\n",
    "b = a.transpose(1,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2905902216768\n",
      "2905902433856\n"
     ]
    }
   ],
   "source": [
    "print(id(a))\n",
    "print(id(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.6806, 0.2511, 0.9525, 0.2058],\n",
       "        [0.9230, 0.0633, 0.9435, 0.4459]])"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "a[0,:] = 9\n",
    "b\n",
    "assert torch.equal(b[:,0], torch.tensor([9.]*4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([9, 9, 9, 9])"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " torch.tensor([9]*4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([9., 9., 9., 9.])"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.equal(a, b.transpose(1,0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2905784361984"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id(net.G[-2].__dict__['_parameters']['weight'].data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2905784361472"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id(net.D[2].__dict__['_parameters']['weight'].data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0521, -0.0775, -0.0744,  ..., -0.0725, -0.1654, -0.1301],\n",
       "        [-0.0731, -0.0631, -0.0613,  ..., -0.0661, -0.2164, -0.1361],\n",
       "        [-0.0520, -0.0943, -0.1003,  ..., -0.0813, -0.2067, -0.1428],\n",
       "        ...,\n",
       "        [-0.0612, -0.0680, -0.0747,  ..., -0.0412, -0.2129, -0.1440],\n",
       "        [-0.0582, -0.0743, -0.0969,  ..., -0.0999, -0.1562, -0.1525],\n",
       "        [-0.0906, -0.0473, -0.0539,  ..., -0.0384, -0.1802, -0.1583]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.G[-2].__dict__['_parameters']['weight'].data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aa"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "adv",
   "language": "python",
   "name": "adv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
