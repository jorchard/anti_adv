{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generativity and Adversarial Gradients\n",
    "\n",
    "**Purpose:** Quick check to assert that the adversiarial gradients point to the same object (and not just a copy of weights). \n",
    "\n",
    "note: git commit `f241a9c` , if there is an error and it is fixed, this notebook will not run appropriately\n",
    "\n",
    "**Result:** Matrices do not refer to the same object. I believe the transpose operation is copying a new object. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "from typing import List\n",
    "\n",
    "import copy\n",
    "import os\n",
    "import pathlib\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as T\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Globals\n",
    "DATADIR = os.path.join(\"..\", \"data\", \"MNIST\")    # assume running from /notebooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using device = 'cpu'\n"
     ]
    }
   ],
   "source": [
    "# In case you are fortunate enough to have access to a GPU...\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f\"using {device = }\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw(X, img_size: (28,28)):\n",
    "    def draw_single(x): \n",
    "        with torch.no_grad():\n",
    "            plt.imshow(x.detach().cpu().numpy().reshape(img_size), cmap='gray');\n",
    "            plt.axis('off');\n",
    "\n",
    "    if len(X.shape)==4 or len(X.shape)==2:  # display a batch\n",
    "        N = X.shape[0]\n",
    "        plt.figure(figsize=(15,3))\n",
    "        for k,xx in enumerate(X):\n",
    "            plt.subplot(1,10,k+1)\n",
    "            draw_single(xx)\n",
    "    else:\n",
    "        draw_single(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data: MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# You can change img_size to 14 if you want to use smaller (14x14) images.\n",
    "\n",
    "\n",
    "img_size = 28\n",
    "ds_full = torchvision.datasets.MNIST(DATADIR, train=True, download=True,\n",
    "                                transform=T.Compose([\n",
    "                                T.Resize((img_size,img_size)),\n",
    "                                T.ToTensor(),\n",
    "                                T.Lambda((lambda x: torch.flatten(x))),\n",
    "                            ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can change img_size to 14 if you want to use smaller (14x14) images.\n",
    "img_size = 28\n",
    "ds_test = torchvision.datasets.MNIST(DATADIR, train=False, download=True,\n",
    "                                transform=T.Compose([\n",
    "                                T.Resize((img_size,img_size)),\n",
    "                                T.ToTensor(),\n",
    "                                T.Lambda((lambda x: torch.flatten(x))),\n",
    "                            ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ds = ds_full\n",
    "n = 1024*2\n",
    "n_samples = n if n <= len(ds_full) else len(ds_full)\n",
    "\n",
    "ds = torch.utils.data.Subset(ds_full, range(n_samples))\n",
    "dl = torch.utils.data.DataLoader(ds, batch_size=32, shuffle=True)\n",
    "dl_test = torch.utils.data.DataLoader(ds_test, batch_size=256)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyNet(nn.Module):\n",
    "    '''\n",
    "     net = MyNet(img_size=28)\n",
    "     \n",
    "     Creates a neural network to do classification on MNIST.\n",
    "     It assumes the images will be (img_size)x(img_size).\n",
    "     \n",
    "     It projects to a latent space.\n",
    "     From that latent space, it:\n",
    "      1) projects to an output classification layer (log softmax), and\n",
    "      2) projects back down through the network to a reconstruction of the input.\n",
    "     \n",
    "    '''\n",
    "    def __init__(self, img_size=28, latent_dim=5):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Discriminative network\n",
    "        self.D = nn.ModuleList()\n",
    "        \n",
    "        # Input -> Hidden 1\n",
    "        self.D.append(nn.Linear(img_size**2, 100))\n",
    "        self.D.append(nn.ReLU())\n",
    "        \n",
    "        # Hidden 1 -> Hidden 2\n",
    "        self.D.append(nn.Linear(100, latent_dim))\n",
    "        self.D.append(nn.ReLU())\n",
    "        \n",
    "        # Classifier\n",
    "        self.classifier = nn.Sequential(\n",
    "                            nn.Linear(latent_dim, 10),\n",
    "                            nn.LogSoftmax(dim=-1),\n",
    "                            )\n",
    "\n",
    "        # The generative network\n",
    "        self.G = nn.ModuleList()\n",
    "        \n",
    "        # Hidden 2 -> Hidden 1\n",
    "        self.G.append(nn.Linear(latent_dim, 100))\n",
    "        self.G.append(nn.ReLU())\n",
    "        \n",
    "        # Hidden 1 -> Input\n",
    "        self.G.append(nn.Linear(100, img_size**2))\n",
    "        self.G.append(nn.Sigmoid())\n",
    "        \n",
    "        # Tie the weights of D and G\n",
    "        #TODO check if pointer or copy\n",
    "        # check pytorch source to see transpose\n",
    "        # https://pytorch.org/docs/stable/generated/torch.transpose.html#torch.transpose\n",
    "        # ^ shares underlying data, so will not return new object\n",
    "        self.G[-2].weight.data = self.D[0].weight.data.transpose(1,0)\n",
    "        self.G[-4].weight.data = self.D[2].weight.data.transpose(1,0)\n",
    "        self.G[-4].bias.data = self.D[0].bias.data\n",
    "        \n",
    "        self.classifier_loss = nn.NLLLoss()\n",
    "        self.recon_loss = nn.BCELoss()\n",
    "        self.losses = []\n",
    "        self.to(device)\n",
    "        \n",
    "        # checkpoint states\n",
    "        self.optimizer = None\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        '''Latent -> Classification'''\n",
    "        return self.classifier(self.discriminate(x))\n",
    "\n",
    "    \n",
    "    def ae(self,x):\n",
    "        return self.generate(self.discriminate(x))\n",
    "\n",
    "    \n",
    "    def discriminate(self, x):\n",
    "        '''Input -> Latent'''\n",
    "        for d in self.D:\n",
    "            x = d(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "    def generate(self, z):\n",
    "        '''\n",
    "         Latent -> Input\n",
    "         x_had = net.generate(z)\n",
    "         \n",
    "         Runs the network in reverse, generating a batch of inputs from\n",
    "         a batch of latent vectors.\n",
    "         \n",
    "         Inputs:\n",
    "          z      (D,latent_dim) tensor of latent vectors\n",
    "          \n",
    "         Outputs:\n",
    "          x_hat  (D,784) tensor containing the batch of inputs\n",
    "        '''\n",
    "        for g in self.G:\n",
    "            z = g(z)\n",
    "        return z\n",
    "    \n",
    "      \n",
    "    def learn(self, \n",
    "              dl, \n",
    "              optimizer=None, \n",
    "              epochs=10, \n",
    "              beta=0.,\n",
    "              checkpoints=[],\n",
    "              path: str=None,\n",
    "              plot_loss=True):\n",
    "        '''\n",
    "         net.learn(dl, optimizer=None, epochs=10, beta=0.)\n",
    "         \n",
    "         Train the network on the dataset represented by the DataLoader dl.\n",
    "         The default optimizer is Adam().\n",
    "         \n",
    "         The targets for the dataset are assumed to be class indices.\n",
    "         \n",
    "         beta is the weight for the reconstruction loss.\n",
    "         \n",
    "         Args:\n",
    "             dl (Dataloader): \n",
    "             checkpoints (Boolean|List[int]): if True, save every 10-epochs. if List[int], save each listed epoch.\n",
    "             path (str): optional path to save model checkpoints.\n",
    "        '''\n",
    "        if optimizer is None:\n",
    "            print('Need to specify an optimizer')\n",
    "            return\n",
    "        else:\n",
    "            self.optimizer = optimizer\n",
    "        \n",
    "        for epoch in tqdm(range(epochs)):\n",
    "            total_loss = 0.\n",
    "            count = 0.\n",
    "            for x, t in dl:\n",
    "                x = x.to(device)   # for use with a GPU\n",
    "                t = t.to(device)\n",
    "                z = self.discriminate(x)\n",
    "                y = self.classifier(z)\n",
    "                xhat = self.generate(z)\n",
    "                loss = self.classifier_loss(y, t) + beta*self.recon_loss(xhat, x)\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                # set generator weights to equal discirminator weights\n",
    "                # hack fix\n",
    "                #self.G[0].weight.data = self.D[2].weight.data.transpose(1,0)\n",
    "                #self.G[-2].weight.data = self.D[0].weight.data.transpose(1,0)\n",
    "                self.G[-2].weight = torch.nn.Parameter(self.D[0].weight.transpose(1,0))\n",
    "                self.G[-4].weight = torch.nn.Parameter(self.D[2].weight.transpose(1,0))\n",
    "                # delete above hack\n",
    "                total_loss += loss.item()*len(t)\n",
    "                count += 1.\n",
    "            self.losses.append(total_loss/len(dl.dataset))\n",
    "            #print(f'Epoch: {epoch}, loss: {total_loss/count}')\n",
    "            if checkpoints:\n",
    "                self.checkpoint(epoch, checkpoints, path)\n",
    "        \n",
    "        if plot_loss:        \n",
    "            plt.figure(figsize=(4,4))\n",
    "            plt.plot(self.losses); plt.yscale('log');\n",
    "\n",
    "\n",
    "    def checkpoint(self, \n",
    "                   epoch: int, \n",
    "                   checkpoints: List[int]=[],\n",
    "                   path: str=\"model-checkpoints.pt\"):\n",
    "        \"\"\" Save model checkpoints. \n",
    "        \n",
    "            Args:\n",
    "                epoch (int): Current training epoch.\n",
    "                checkpoints (List[int]): list of epochs to save model at. if True, save every 10.model \n",
    "                path (str): path to save model.pt\n",
    "                \n",
    "        \"\"\"\n",
    "        \n",
    "        def save_checkpoint(self, epoch, path):\n",
    "            path = path.split(\".pt\")[0] + f\"-{epoch}\" + \".pt\"\n",
    "            torch.save({'epoch': epoch,\n",
    "                        'model_state_dict': self.state_dict(),\n",
    "                        'optimizer_state_dict': self.optimizer.state_dict(),\n",
    "                        'loss': self.losses[-1],\n",
    "                        }, \n",
    "                        path) \n",
    "        \n",
    "        if checkpoints is True:\n",
    "            if epoch % 10 == 0: \n",
    "                save_checkpoint(self, epoch, path)\n",
    "        elif epoch in checkpoints:\n",
    "            save_checkpoint(self, epoch, path)     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assert Objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = MyNet(28, latent_dim=8)#.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below: The tensors start out with identical weight values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#         self.G[-2].weight.data = self.D[0].weight.data.transpose(1,0)\n",
    "#         self.G[-4].weight.data = self.D[2].weight.data.transpose(1,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert torch.equal(net.G[-2].weight.data.T, net.D[0].weight.data)\n",
    "assert torch.equal(net.G[-4].weight.data.T, net.D[2].weight.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-ecdee764de52>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32massert\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mequal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mG\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mD\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32massert\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mequal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mG\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mD\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "assert torch.equal(net.G[0].weight.data.T, net.D[2].weight.data)\n",
    "assert torch.equal(net.G[-2].weight.data.T, net.D[2].weight.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below: but the pointers do not reference the same object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-c2b90cc2091d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32massert\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mG\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mD\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32massert\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mG\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mD\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32massert\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mG\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mD\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "assert net.G[-2].weight.data is net.D[0].weight.data.transpose(1,0)\n",
    "assert net.G[-4].weight.data is net.D[2].weight.data.transpose(1,0)\n",
    "assert net.G[-4].bias.data is net.D[0].bias.data.transpose(1,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-9b97fd35e612>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32massert\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mG\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mD\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32massert\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mG\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mD\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32massert\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mG\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mD\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "assert net.G[-2] is net.D[0]\n",
    "assert net.G[-4] is net.D[2]\n",
    "assert net.G[-4] is net.D[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-39b9d558776f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32massert\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mG\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mD\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32massert\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mG\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mD\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32massert\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mG\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mD\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "assert net.G[-2].weight.data is net.D[0].weight.data.transpose(1,0)\n",
    "assert net.G[-4].weight is net.D[2].weight\n",
    "assert net.G[-4].bias is net.D[0].bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like these asserts will fail, not because the pointers aren't to the same object, but because the transpose operation breaks the `is` comparison. \n",
    "\n",
    "So, have to just test if updates to one affect the other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO check if pointer or copy\n",
    "#self.G[-2].weight.data = self.D[0].weight.data.transpose(1,0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider the zero-th row of `net.G[-2]` and the zero-th column of `net.D[0]` should be equivalent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below: on update of generator, discriminator weights shouldn't change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.G[-2].weight.data[0:1,] = 1\n",
    "\n",
    "assert not net.G[-2].weight.data is net.D[0].weight.data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below: but on update of discriminator, generator _should_ update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.D[0].weight.data[0:1,] = 9\n",
    "\n",
    "assert torch.equal(net.D[0].weight.data[0:1,], net.G[-2].weight.data.transpose(1,0)[0:1,])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below: but forcing a chage to `net.G` does update."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.G[-2].weight.data[:,0] = 9\n",
    "\n",
    "assert torch.equal(net.D[0].weight.data[0:1,], net.G[-2].weight.data.transpose(1,0)[0:1,])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Net and Assert Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:02<00:00,  2.31it/s]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "img_size = 28\n",
    "net = MyNet(img_size, latent_dim=8)#.to(device)\n",
    "\n",
    "g_init = net.G[-2].weight.data\n",
    "d_init = net.D[0].weight.data\n",
    "\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=0.001)\n",
    "checkpoints = False\n",
    "path = os.path.join(DATADIR, f\"mnist-debug-{len(dl)}-checkpoint.pt\")\n",
    "\n",
    "net.learn(dl, \n",
    "          optimizer=optimizer, \n",
    "          epochs=5, \n",
    "          beta=3., \n",
    "          checkpoints=checkpoints,\n",
    "          path=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#.G[-2].weight.data = self.D[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert torch.equal(net.G[-2].weight.data.T, net.D[0].weight.data)\n",
    "assert torch.equal(net.G[-4].weight.data.T, net.D[2].weight.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again: `net.D` gradient indices are `0->2` (and bias at `0`).   while `net.G` gradients, are the reverse `-4 -> -2`.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for i=-2, j=0\n",
      "for i=-4, j=2\n"
     ]
    }
   ],
   "source": [
    "d = [0, 2]\n",
    "g = [-2,-4]\n",
    "\n",
    "\n",
    "for i,j in zip(g,d):\n",
    "    print(f\"for {i=}, {j=}\")\n",
    "    assert torch.equal(net.G[i].weight.data, net.D[j].weight.data.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0303, -0.0399, -0.0260, -0.0038,  0.0216],\n",
       "        [ 0.0122, -0.0238, -0.0233, -0.0348, -0.0411],\n",
       "        [-0.0105, -0.0353, -0.0351, -0.0294, -0.0014],\n",
       "        [-0.0173,  0.0119,  0.0218,  0.0241, -0.0204],\n",
       "        [-0.0292, -0.0383,  0.0259, -0.0083, -0.0353]])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.G[-2].weight.data[:5,:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0303,  0.0122, -0.0105, -0.0173, -0.0292],\n",
       "        [-0.0399, -0.0238, -0.0353,  0.0119, -0.0383],\n",
       "        [-0.0260, -0.0233, -0.0351,  0.0218,  0.0259],\n",
       "        [-0.0038, -0.0348, -0.0294,  0.0241, -0.0083],\n",
       "        [ 0.0216, -0.0411, -0.0014, -0.0204, -0.0353]])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.D[0].weight.data[:5,:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-60-c2ca950c601e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mequal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg_init\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mG\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "assert not torch.equal(g_init, net.G[-2].weight.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-61-525d96ece44b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mequal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md_init\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mD\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "assert not torch.equal(d_init, net.D[0].weight.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check object IDs\n",
    "\n",
    "and maybe memory location"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "note: ID is of the pointer, not the object, it seems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5154044608"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id(net.G[-2].weight.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5273599040"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id(net.D[0].weight.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 100])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.G[-2].weight.data[0:1,].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 100])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.D[0].weight.data[:,0:1].T.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check Training Checkpoints\n",
    "\n",
    "Does generator update through training?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:22<00:00,  2.24it/s]\n"
     ]
    }
   ],
   "source": [
    "img_size = 28\n",
    "net = MyNet(img_size, latent_dim=8)#.to(device)\n",
    "\n",
    "g_init = net.G[-2].weight.data\n",
    "d_init = net.D[0].weight.data\n",
    "assert torch.equal(d_init, g_init.transpose(1,0))\n",
    "\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=0.001)\n",
    "checkpoints = [0,1,5,10,20,49]\n",
    "path = os.path.join(DATADIR, f\"debug-train-{len(ds)}-checkpoint.pt\")\n",
    "\n",
    "net.learn(dl, \n",
    "          optimizer=optimizer, \n",
    "          epochs=50, \n",
    "          beta=3., \n",
    "          checkpoints=checkpoints,\n",
    "          path=path,\n",
    "          plot_loss=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "plotting epochs: tensor([[-0.0089, -0.0239, -0.0227, -0.0272, -0.0337],\n",
      "        [ 0.0197, -0.0265,  0.0165, -0.0140, -0.0190],\n",
      "        [-0.0180,  0.0212,  0.0101,  0.0297, -0.0250],\n",
      "        [-0.0226,  0.0224,  0.0139, -0.0244, -0.0280],\n",
      "        [-0.0210,  0.0255,  0.0041,  0.0239, -0.0308]])\n",
      "tensor([[-0.0089, -0.0239, -0.0227, -0.0272, -0.0337],\n",
      "        [ 0.0197, -0.0265,  0.0165, -0.0140, -0.0190],\n",
      "        [-0.0180,  0.0212,  0.0101,  0.0297, -0.0250],\n",
      "        [-0.0226,  0.0224,  0.0139, -0.0244, -0.0280],\n",
      "        [-0.0210,  0.0255,  0.0041,  0.0239, -0.0308]])\n",
      "tensor([[-0.0089, -0.0239, -0.0227, -0.0272, -0.0337],\n",
      "        [ 0.0197, -0.0265,  0.0165, -0.0140, -0.0190],\n",
      "        [-0.0180,  0.0212,  0.0101,  0.0297, -0.0250],\n",
      "        [-0.0226,  0.0224,  0.0139, -0.0244, -0.0280],\n",
      "        [-0.0210,  0.0255,  0.0041,  0.0239, -0.0308]])\n",
      "tensor([[-0.0089, -0.0239, -0.0227, -0.0272, -0.0337],\n",
      "        [ 0.0197, -0.0265,  0.0165, -0.0140, -0.0190],\n",
      "        [-0.0180,  0.0212,  0.0102,  0.0297, -0.0250],\n",
      "        [-0.0226,  0.0224,  0.0139, -0.0244, -0.0280],\n",
      "        [-0.0210,  0.0255,  0.0041,  0.0239, -0.0308]])\n",
      "tensor([[-0.0089, -0.0239, -0.0227, -0.0272, -0.0337],\n",
      "        [ 0.0197, -0.0265,  0.0165, -0.0140, -0.0190],\n",
      "        [-0.0180,  0.0212,  0.0101,  0.0297, -0.0250],\n",
      "        [-0.0226,  0.0224,  0.0139, -0.0244, -0.0280],\n",
      "        [-0.0210,  0.0255,  0.0041,  0.0239, -0.0308]])\n",
      "tensor([[-0.0089, -0.0239, -0.0227, -0.0272, -0.0337],\n",
      "        [ 0.0197, -0.0265,  0.0165, -0.0140, -0.0190],\n",
      "        [-0.0180,  0.0212,  0.0101,  0.0297, -0.0250],\n",
      "        [-0.0226,  0.0224,  0.0139, -0.0244, -0.0280],\n",
      "        [-0.0210,  0.0255,  0.0041,  0.0239, -0.0308]])\n"
     ]
    }
   ],
   "source": [
    "paths = [filepath.absolute() for filepath in pathlib.Path(DATADIR).glob(\"debug-*.pt\")]\n",
    "model = copy.deepcopy(net)    # just in case, don't mess with net obj\n",
    "\n",
    "# history of net.G[-2]\n",
    "g_history = []\n",
    "d_history = []\n",
    "print(\"plotting epochs:\", end=\" \")\n",
    "for path in paths:\n",
    "    \n",
    "    # load model checkpoint\n",
    "    checkpoint = torch.load(path)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    epoch = checkpoint['epoch']\n",
    "    model.eval()\n",
    "\n",
    "    g_checkpoint = model.G[-2].weight.data\n",
    "    d_checkpoint = model.D[0].weight.data\n",
    "    \n",
    "    g_history.append(g_checkpoint)\n",
    "    d_history.append(d_checkpoint)\n",
    "    \n",
    "    # draw grad subplot line\n",
    "    #print(f\"{epoch}\", end=\", \")\n",
    "    #draw(torch.sign(x.grad[:10]))\n",
    "    \n",
    "    #draw(g_checkpoint, img_size=(784,100))\n",
    "    \n",
    "    print(g_checkpoint[:5,:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert torch.equal(d_init, g_init.transpose(1,0)) # passes on network instantiation above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "above: since `d_init` and `g_init` are pointers to the network's respective tensors, the assert passing on instantiation, but failing after training (again) indicates that the two matrices diverge throughout training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i = 0\n",
      "i = 1\n",
      "i = 2\n",
      "i = 3\n",
      "i = 4\n",
      "i = 5\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(d_history)):\n",
    "    print(f\"{i = }\")\n",
    "    assert torch.equal(d_history[i], g_history[i].transpose(1,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check again with higher gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "plotting epochs: tensor([[-0.1966, -0.2293, -0.3648,  0.2637, -0.1843],\n",
      "        [ 0.1680,  0.1833, -0.1726,  0.0464,  0.1053],\n",
      "        [ 0.0085,  0.1677,  0.0332,  0.0990,  0.0528],\n",
      "        [-0.0367,  0.0930, -0.1173,  0.0795, -0.1300],\n",
      "        [ 0.2456, -0.0733,  0.2642,  0.1954,  0.0523]])\n",
      "tensor([[-0.2506, -0.2061, -0.3915,  0.2760, -0.1978],\n",
      "        [ 0.1741,  0.1800, -0.1576,  0.0354,  0.0914],\n",
      "        [ 0.0259,  0.1765,  0.0611,  0.1270,  0.0684],\n",
      "        [-0.0077,  0.1196, -0.0519,  0.1385, -0.0982],\n",
      "        [ 0.1490, -0.0926,  0.2355,  0.1523, -0.0211]])\n",
      "tensor([[-0.1977, -0.1555, -0.3723,  0.2570, -0.1783],\n",
      "        [ 0.1672,  0.1783, -0.1513,  0.0343,  0.0874],\n",
      "        [ 0.0153,  0.1844,  0.0623,  0.1371,  0.0614],\n",
      "        [-0.0171,  0.1323, -0.0500,  0.1716, -0.0960],\n",
      "        [ 0.1164, -0.0882,  0.2084,  0.1642, -0.0423]])\n",
      "tensor([[-0.0876, -0.0856, -0.1001,  0.0693, -0.0290],\n",
      "        [ 0.1082,  0.1299, -0.1303,  0.0372,  0.0408],\n",
      "        [ 0.0174,  0.1376,  0.0209,  0.1046,  0.0504],\n",
      "        [-0.0131,  0.0901, -0.0803,  0.1228, -0.0787],\n",
      "        [ 0.0902, -0.0702,  0.1185,  0.1153, -0.0013]])\n",
      "tensor([[-0.0876, -0.0855, -0.1001,  0.0693, -0.0291],\n",
      "        [ 0.1313,  0.1513, -0.1439,  0.0436,  0.0498],\n",
      "        [ 0.0162,  0.1582,  0.0267,  0.1283,  0.0578],\n",
      "        [-0.0220,  0.1147, -0.0823,  0.1597, -0.0974],\n",
      "        [ 0.1049, -0.0895,  0.1558,  0.1583, -0.0157]])\n",
      "tensor([[-0.1139, -0.1166, -0.2286,  0.1752, -0.0786],\n",
      "        [ 0.1568,  0.1745, -0.1517,  0.0367,  0.0750],\n",
      "        [ 0.0113,  0.1848,  0.0505,  0.1349,  0.0578],\n",
      "        [-0.0247,  0.1351, -0.0619,  0.1752, -0.0959],\n",
      "        [ 0.1162, -0.0826,  0.1930,  0.1785, -0.0359]])\n"
     ]
    }
   ],
   "source": [
    "paths = [filepath.absolute() for filepath in pathlib.Path(DATADIR).glob(\"debug-*.pt\")]\n",
    "model = copy.deepcopy(net)    # just in case, don't mess with net obj\n",
    "\n",
    "# history of net.G[-4]\n",
    "g_history = []\n",
    "d_history= []\n",
    "\n",
    "print(\"plotting epochs:\", end=\" \")\n",
    "for path in paths:\n",
    "    \n",
    "    # load model checkpoint\n",
    "    checkpoint = torch.load(path)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    epoch = checkpoint['epoch']\n",
    "    model.eval()\n",
    "\n",
    "    g_checkpoint = model.G[-4].weight.data\n",
    "    d_checkpint = model.D[0].weight.data\n",
    "    \n",
    "    # draw grad subplot line\n",
    "    #print(f\"{epoch}\", end=\", \")\n",
    "    #draw(torch.sign(x.grad[:10]))\n",
    "    \n",
    "    #draw(g_checkpoint, img_size=(100,8))\n",
    "    print(g_checkpoint[:5,:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check on Arbitrary Tensors\n",
    "\n",
    "**Shows**: that referencing a torch tensor pointer can work, update, and not create a copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.rand((2,4))\n",
    "b = a.transpose(1,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5273574656\n",
      "5273571776\n"
     ]
    }
   ],
   "source": [
    "print(id(a))\n",
    "print(id(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2799, 0.9431, 0.6120, 0.8675],\n",
       "        [0.0854, 0.4129, 0.5539, 0.3627]])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "a[0,:] = 9\n",
    "b\n",
    "assert torch.equal(b[:,0], torch.tensor([9.]*4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([9, 9, 9, 9])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " torch.tensor([9]*4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([9., 9., 9., 9.])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.equal(a, b.transpose(1,0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5274355392"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id(net.G[-2].__dict__['_parameters']['weight'].data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5274304256"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id(net.D[2].__dict__['_parameters']['weight'].data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0089, -0.0239, -0.0227,  ..., -0.0078,  0.0021, -0.0294],\n",
       "        [ 0.0197, -0.0265,  0.0165,  ...,  0.0134,  0.0241,  0.0060],\n",
       "        [-0.0180,  0.0212,  0.0101,  ..., -0.0050,  0.0018, -0.0182],\n",
       "        ...,\n",
       "        [ 0.0247,  0.0205,  0.0153,  ...,  0.0272, -0.0012,  0.0241],\n",
       "        [-0.0069,  0.0233, -0.0404,  ...,  0.0079, -0.0254,  0.0142],\n",
       "        [-0.0072,  0.0029, -0.0076,  ..., -0.0167, -0.0380,  0.0052]])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.G[-2].__dict__['_parameters']['weight'].data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "adv",
   "language": "python",
   "name": "adv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
