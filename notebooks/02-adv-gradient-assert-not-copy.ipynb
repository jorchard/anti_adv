{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generativity and Adversarial Gradients\n",
    "\n",
    "**Purpose:** Quick check to assert that the adversiarial gradients point to the same object (and not just a copy of weights). \n",
    "\n",
    "note: git commit `f241a9c` , if there is an error and it is fixed, this notebook will not run appropriately\n",
    "\n",
    "**Result:** Matrices do not refer to the same object. I believe the transpose operation is copying a new object. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "import copy\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as T\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using device = 'cuda'\n"
     ]
    }
   ],
   "source": [
    "# In case you are fortunate enough to have access to a GPU...\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f\"using {device = }\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Data: MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# You can change img_size to 14 if you want to use smaller (14x14) images.\n",
    "img_size = 28\n",
    "ds_full = torchvision.datasets.MNIST('./files/', train=True, download=True,\n",
    "                                transform=T.Compose([\n",
    "                                T.Resize((img_size,img_size)),\n",
    "                                T.ToTensor(),\n",
    "                                T.Lambda((lambda x: torch.flatten(x))),\n",
    "                            ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# You can change img_size to 14 if you want to use smaller (14x14) images.\n",
    "img_size = 28\n",
    "ds_test = torchvision.datasets.MNIST('./files/', train=False, download=True,\n",
    "                                transform=T.Compose([\n",
    "                                T.Resize((img_size,img_size)),\n",
    "                                T.ToTensor(),\n",
    "                                T.Lambda((lambda x: torch.flatten(x))),\n",
    "                            ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#ds = ds_full\n",
    "n = 1024*2\n",
    "n_samples = n if n <= len(ds_full) else len(ds_full)\n",
    "\n",
    "ds = torch.utils.data.Subset(ds_full, range(n_samples))\n",
    "dl = torch.utils.data.DataLoader(ds, batch_size=32, shuffle=True)\n",
    "dl_test = torch.utils.data.DataLoader(ds_test, batch_size=256)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class MyNet(nn.Module):\n",
    "    '''\n",
    "     net = MyNet(img_size=28)\n",
    "     \n",
    "     Creates a neural network to do classification on MNIST.\n",
    "     It assumes the images will be (img_size)x(img_size).\n",
    "     \n",
    "     It projects to a latent space.\n",
    "     From that latent space, it:\n",
    "      1) projects to an output classification layer (log softmax), and\n",
    "      2) projects back down through the network to a reconstruction of the input.\n",
    "     \n",
    "    '''\n",
    "    def __init__(self, img_size=28, latent_dim=5):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Discriminative network\n",
    "        self.D = nn.ModuleList()\n",
    "        \n",
    "        # Input -> Hidden 1\n",
    "        self.D.append(nn.Linear(img_size**2, 100))\n",
    "        self.D.append(nn.ReLU())\n",
    "        \n",
    "        # Hidden 1 -> Hidden 2\n",
    "        self.D.append(nn.Linear(100, latent_dim))\n",
    "        self.D.append(nn.ReLU())\n",
    "        \n",
    "        # Classifier\n",
    "        self.classifier = nn.Sequential(\n",
    "                            nn.Linear(latent_dim, 10),\n",
    "                            nn.LogSoftmax(dim=-1),\n",
    "                            )\n",
    "\n",
    "        # The generative network\n",
    "        self.G = nn.ModuleList()\n",
    "        \n",
    "        # Hidden 2 -> Hidden 1\n",
    "        self.G.append(nn.Linear(latent_dim, 100))\n",
    "        self.G.append(nn.ReLU())\n",
    "        \n",
    "        # Hidden 1 -> Input\n",
    "        self.G.append(nn.Linear(100, img_size**2))\n",
    "        self.G.append(nn.Sigmoid())\n",
    "        \n",
    "        # Tie the weights of D and G\n",
    "        #TODO check if pointer or copy\n",
    "        self.G[-2].weight.data = self.D[0].weight.data.transpose(1,0)\n",
    "        self.G[-4].weight.data = self.D[2].weight.data.transpose(1,0)\n",
    "        self.G[-4].bias.data = self.D[0].bias.data\n",
    "        \n",
    "        self.classifier_loss = nn.NLLLoss()\n",
    "        self.recon_loss = nn.BCELoss()\n",
    "        self.losses = []\n",
    "        self.to(device)\n",
    "        \n",
    "        # checkpoint states\n",
    "        self.optimizer = None\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        '''Latent -> Classification'''\n",
    "        return self.classifier(self.discriminate(x))\n",
    "\n",
    "    \n",
    "    def ae(self,x):\n",
    "        return self.generate(self.discriminate(x))\n",
    "\n",
    "    \n",
    "    def discriminate(self, x):\n",
    "        '''Input -> Latent'''\n",
    "        for d in self.D:\n",
    "            x = d(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "    def generate(self, z):\n",
    "        '''\n",
    "         Latent -> Input\n",
    "         x_had = net.generate(z)\n",
    "         \n",
    "         Runs the network in reverse, generating a batch of inputs from\n",
    "         a batch of latent vectors.\n",
    "         \n",
    "         Inputs:\n",
    "          z      (D,latent_dim) tensor of latent vectors\n",
    "          \n",
    "         Outputs:\n",
    "          x_hat  (D,784) tensor containing the batch of inputs\n",
    "        '''\n",
    "        for g in self.G:\n",
    "            z = g(z)\n",
    "        return z\n",
    "    \n",
    "      \n",
    "    def learn(self, \n",
    "              dl, \n",
    "              optimizer=None, \n",
    "              epochs=10, \n",
    "              beta=0.,\n",
    "              checkpoints=[],\n",
    "              path: str=None):\n",
    "        '''\n",
    "         net.learn(dl, optimizer=None, epochs=10, beta=0.)\n",
    "         \n",
    "         Train the network on the dataset represented by the DataLoader dl.\n",
    "         The default optimizer is Adam().\n",
    "         \n",
    "         The targets for the dataset are assumed to be class indices.\n",
    "         \n",
    "         beta is the weight for the reconstruction loss.\n",
    "         \n",
    "         Args:\n",
    "         \n",
    "             checkpoints (Boolean|List[int]): if True, save every 10-epochs. if List[int], save each listed epoch.\n",
    "             path (str): optional path to save model checkpoints.\n",
    "        '''\n",
    "        if optimizer is None:\n",
    "            print('Need to specify an optimizer')\n",
    "            return\n",
    "        else:\n",
    "            self.optimizer = optimizer\n",
    "        \n",
    "        for epoch in tqdm(range(epochs)):\n",
    "            total_loss = 0.\n",
    "            count = 0.\n",
    "            for x, t in dl:\n",
    "                x = x.to(device)   # for use with a GPU\n",
    "                t = t.to(device)\n",
    "                z = self.discriminate(x)\n",
    "                y = self.classifier(z)\n",
    "                xhat = self.generate(z)\n",
    "                loss = self.classifier_loss(y, t) + beta*self.recon_loss(xhat, x)\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                total_loss += loss.item()*len(t)\n",
    "                count += 1.\n",
    "            self.losses.append(total_loss/len(dl.dataset))\n",
    "            #print(f'Epoch: {epoch}, loss: {total_loss/count}')\n",
    "            if checkpoints:\n",
    "                self.checkpoint(epoch, checkpoints, path)\n",
    "                \n",
    "        plt.figure(figsize=(4,4))\n",
    "        plt.plot(self.losses); plt.yscale('log');\n",
    "\n",
    "\n",
    "    def checkpoint(self, \n",
    "                   epoch: int, \n",
    "                   checkpoints: List[int]=[],\n",
    "                   path: str=\"model-checkpoints.pt\"):\n",
    "        \"\"\" Save model checkpoints. \n",
    "        \n",
    "            Args:\n",
    "                epoch (int): Current training epoch.\n",
    "                checkpoints (List[int]): list of epochs to save model at. if True, save every 10.model \n",
    "                path (str): path to save model.pt\n",
    "                \n",
    "        \"\"\"\n",
    "        \n",
    "        def save_checkpoint(self, epoch, path):\n",
    "            path = path.split(\".pt\")[0] + f\"-{epoch}\" + \".pt\"\n",
    "            torch.save({'epoch': epoch,\n",
    "                        'model_state_dict': self.state_dict(),\n",
    "                        'optimizer_state_dict': self.optimizer.state_dict(),\n",
    "                        'loss': self.losses[-1],\n",
    "                        }, \n",
    "                        path) \n",
    "        \n",
    "        if checkpoints is True:\n",
    "            if epoch % 10 == 0: \n",
    "                save_checkpoint(self, epoch, path)\n",
    "        elif epoch in checkpoints:\n",
    "            save_checkpoint(self, epoch, path)     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Assert Objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "net = MyNet(8*8, latent_dim=8)#.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-59-61342d16c1a8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32massert\u001b[0m \u001b[0mnet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mG\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mnet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mD\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32massert\u001b[0m \u001b[0mnet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mG\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mnet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mD\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32massert\u001b[0m \u001b[0mnet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mG\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mnet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mD\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "assert net.G[-2].weight.data is net.D[0].weight.data\n",
    "assert net.G[-4].weight.data is net.D[2].weight.data\n",
    "assert net.G[-4].bias.data is net.D[0].bias.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-60-3bdb5279c86e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32massert\u001b[0m \u001b[0mnet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mG\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mnet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mD\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32massert\u001b[0m \u001b[0mnet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mG\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mnet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mD\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32massert\u001b[0m \u001b[0mnet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mG\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mnet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mD\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "assert net.G[-2].weight.data is net.D[0].weight.data.T\n",
    "assert net.G[-4].weight is net.D[2].weight\n",
    "assert net.G[-4].bias is net.D[0].bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Looks like these asserts will fail, not because the pointers aren't to the same object, but because the transpose operation breaks the `is` comparison. \n",
    "\n",
    "So, have to just test if updates to one affect the other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#TODO check if pointer or copy\n",
    "#self.G[-2].weight.data = self.D[0].weight.data.transpose(1,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-77-fdaf0b322346>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mnet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mG\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32massert\u001b[0m \u001b[0mnet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mG\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mnet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mD\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "net.G[-2].weight.data[0:1,] = 1\n",
    "\n",
    "assert net.G[-2].weight.data is net.D[0].weight.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]], device='cuda:0')"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.G[-2].weight.data[0:1,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.0133, -0.0125,  0.0047, -0.0097,  0.0132,  0.0130,  0.0105, -0.0084,\n",
       "         0.0037, -0.0114,  0.0008, -0.0023,  0.0139, -0.0043, -0.0039,  0.0100,\n",
       "        -0.0152, -0.0136, -0.0003, -0.0043, -0.0051, -0.0006,  0.0102, -0.0050,\n",
       "         0.0110, -0.0043, -0.0083, -0.0109,  0.0017,  0.0114,  0.0146, -0.0126,\n",
       "        -0.0108,  0.0077, -0.0142,  0.0042,  0.0122, -0.0142,  0.0009,  0.0111,\n",
       "         0.0054, -0.0150,  0.0089,  0.0064, -0.0077, -0.0106, -0.0036, -0.0107,\n",
       "        -0.0134,  0.0117, -0.0123,  0.0149,  0.0074, -0.0092, -0.0153, -0.0041,\n",
       "        -0.0054,  0.0149, -0.0154, -0.0085, -0.0019,  0.0110, -0.0107,  0.0119,\n",
       "        -0.0139, -0.0012,  0.0006, -0.0119,  0.0068, -0.0064,  0.0088, -0.0004,\n",
       "        -0.0117, -0.0039, -0.0091,  0.0115,  0.0101,  0.0005,  0.0014, -0.0112,\n",
       "        -0.0088,  0.0027,  0.0019,  0.0111, -0.0138, -0.0031,  0.0107,  0.0038,\n",
       "         0.0042, -0.0010,  0.0101,  0.0138, -0.0152, -0.0091,  0.0131, -0.0086,\n",
       "         0.0029, -0.0091, -0.0125, -0.0070], device='cuda:0')"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.D[0].weight.data[:,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Net and Assert Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 50/50 [00:24<00:00,  2.03it/s]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "img_size = 28\n",
    "net = MyNet(img_size, latent_dim=8)#.to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=0.001)\n",
    "checkpoints = False\n",
    "#path = f\"data/mnist-{len(dl)}-checkpoint.pt\"\n",
    "\n",
    "net.learn(dl, \n",
    "          optimizer=optimizer, \n",
    "          epochs=50, \n",
    "          beta=3., \n",
    "          checkpoints=checkpoints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for i=-2, j=0\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-145-1fb583d57729>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mg\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0md\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"for {i=}, {j=}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[1;32massert\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mequal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mG\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mD\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "g = [-2,-4]\n",
    "d = [0, 2]\n",
    "\n",
    "for i,j in zip(g,d):\n",
    "    print(f\"for {i=}, {j=}\")\n",
    "    assert torch.equal(net.G[i].weight.data, net.D[j].weight.data.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0421, -0.1027, -0.0887, -0.0810, -0.1047],\n",
       "        [-0.0423, -0.1020, -0.0631, -0.1103, -0.0797],\n",
       "        [-0.0731, -0.0900, -0.0612, -0.0843, -0.1029],\n",
       "        [-0.0583, -0.1042, -0.1048, -0.0953, -0.0914],\n",
       "        [-0.0605, -0.0500, -0.0737, -0.1257, -0.0463]], device='cuda:0')"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.G[-2].weight.data[:5,:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0315,  0.0320,  0.0012,  0.0150,  0.0161],\n",
       "        [-0.0310, -0.0298, -0.0176, -0.0327,  0.0244],\n",
       "        [-0.0173,  0.0089,  0.0108, -0.0336,  0.0005],\n",
       "        [ 0.0079, -0.0209,  0.0042, -0.0095, -0.0317],\n",
       "        [-0.0327, -0.0071, -0.0303, -0.0197,  0.0285]], device='cuda:0')"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.D[0].weight.data[:5,:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "note: ID is of the pointer, not the object, it seems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2218482434368"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id(net.G[-2].weight.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2218482622848"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id(net.D[0].weight.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 100])"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.G[-2].weight.data[0:1,].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 100])"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.D[0].weight.data[:,0:1].T.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0421, -0.1027, -0.0887, -0.0810, -0.1047, -0.0447, -0.0380, -0.0899,\n",
       "         -0.7438, -0.0936, -0.0940, -0.0934, -0.3122, -0.0849, -0.0620, -0.0655,\n",
       "         -0.1028, -0.0527, -0.0633, -0.0934, -0.0674, -0.0363, -0.0759, -0.0484,\n",
       "         -0.0934, -0.0781, -0.0563, -0.0569, -0.0354, -0.0805, -0.1186, -0.0926,\n",
       "         -0.0558, -0.0648, -0.0511, -0.0938, -0.0799, -0.0925, -0.0421, -0.0501,\n",
       "         -0.0855, -0.3286, -0.0948, -0.0963, -0.0506, -0.0907, -0.0520, -0.0568,\n",
       "         -0.0710, -0.0980, -0.4106, -0.0503, -0.0804, -0.1271, -0.0857, -0.0699,\n",
       "         -0.0740, -0.1021, -0.0987, -0.0509, -0.0634, -0.0939, -0.1103, -0.1668,\n",
       "         -0.0822, -0.0908, -0.0537, -0.3880, -0.0813, -0.0883, -0.1079, -0.0494,\n",
       "         -0.1145, -0.1281, -0.0737, -0.0662, -0.6201, -0.0688, -0.0391, -0.1074,\n",
       "         -0.1131, -0.0830, -0.0964, -0.1020, -0.1239, -0.1141, -0.0836, -0.0765,\n",
       "         -0.1162, -0.7582,  0.0107, -0.0728, -0.3588, -0.0708, -0.0894, -0.0436,\n",
       "         -0.0946, -0.0394, -0.8551, -0.1009]], device='cuda:0')"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.G[-2].weight.data[0:1,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 3.1472e-02],\n",
       "        [-3.1008e-02],\n",
       "        [-1.7325e-02],\n",
       "        [ 7.9185e-03],\n",
       "        [-3.2723e-02],\n",
       "        [ 2.6506e-02],\n",
       "        [ 3.1762e-02],\n",
       "        [ 1.0523e-02],\n",
       "        [ 1.7864e-02],\n",
       "        [-2.0025e-02],\n",
       "        [ 7.1609e-03],\n",
       "        [-2.0909e-02],\n",
       "        [-3.3396e-02],\n",
       "        [-1.2313e-02],\n",
       "        [ 2.7375e-02],\n",
       "        [ 5.5752e-03],\n",
       "        [-4.3411e-04],\n",
       "        [ 3.3317e-02],\n",
       "        [ 8.9496e-03],\n",
       "        [-2.4617e-02],\n",
       "        [ 1.3629e-02],\n",
       "        [ 3.0907e-02],\n",
       "        [-4.7325e-03],\n",
       "        [ 2.1628e-02],\n",
       "        [-1.8191e-02],\n",
       "        [-5.3357e-03],\n",
       "        [ 2.2850e-02],\n",
       "        [ 1.0913e-02],\n",
       "        [ 3.5144e-02],\n",
       "        [ 4.3305e-03],\n",
       "        [-1.6372e-02],\n",
       "        [-6.2503e-05],\n",
       "        [ 1.4757e-02],\n",
       "        [ 4.0690e-03],\n",
       "        [ 2.6188e-02],\n",
       "        [-2.4690e-02],\n",
       "        [-7.1720e-03],\n",
       "        [-2.1473e-02],\n",
       "        [ 3.0564e-02],\n",
       "        [ 2.3339e-02],\n",
       "        [-1.0586e-02],\n",
       "        [ 1.0492e-03],\n",
       "        [-2.0740e-02],\n",
       "        [-2.6258e-02],\n",
       "        [ 1.8942e-02],\n",
       "        [-1.7957e-02],\n",
       "        [ 2.3000e-02],\n",
       "        [ 1.5509e-02],\n",
       "        [ 3.5170e-03],\n",
       "        [-2.2162e-02],\n",
       "        [-3.0229e-02],\n",
       "        [ 3.1603e-02],\n",
       "        [-9.4750e-03],\n",
       "        [ 1.2243e-02],\n",
       "        [ 2.5358e-02],\n",
       "        [ 1.0765e-03],\n",
       "        [-3.3252e-03],\n",
       "        [-3.0179e-02],\n",
       "        [-2.5425e-02],\n",
       "        [ 2.4496e-02],\n",
       "        [ 1.6643e-02],\n",
       "        [-9.1756e-03],\n",
       "        [-8.1412e-03],\n",
       "        [ 2.9818e-02],\n",
       "        [-9.6297e-03],\n",
       "        [-1.9345e-02],\n",
       "        [ 1.7207e-02],\n",
       "        [-2.4118e-02],\n",
       "        [ 7.6324e-03],\n",
       "        [-1.9618e-02],\n",
       "        [-3.5481e-02],\n",
       "        [ 1.6475e-02],\n",
       "        [-1.5905e-02],\n",
       "        [-4.5571e-03],\n",
       "        [-4.0643e-03],\n",
       "        [ 1.6893e-02],\n",
       "        [ 2.7793e-02],\n",
       "        [ 4.2423e-03],\n",
       "        [ 3.1677e-02],\n",
       "        [-2.8837e-02],\n",
       "        [-3.0426e-02],\n",
       "        [-1.0774e-02],\n",
       "        [-2.5168e-03],\n",
       "        [-2.0150e-02],\n",
       "        [-1.2719e-02],\n",
       "        [-3.5649e-02],\n",
       "        [-1.1211e-02],\n",
       "        [-4.9466e-03],\n",
       "        [-2.3636e-02],\n",
       "        [ 1.1949e-02],\n",
       "        [ 1.0737e-02],\n",
       "        [-2.9678e-03],\n",
       "        [ 2.9005e-02],\n",
       "        [ 5.4262e-04],\n",
       "        [-1.8951e-02],\n",
       "        [-3.2482e-02],\n",
       "        [-2.4073e-02],\n",
       "        [ 3.0786e-02],\n",
       "        [-2.6254e-02],\n",
       "        [-2.3867e-02]], device='cuda:0')"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.D[0].weight.data[:,0:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.0000e+00,  1.0000e+00,  1.0000e+00,  ...,  1.0000e+00,\n",
       "          1.0000e+00,  1.0000e+00],\n",
       "        [-1.1134e-02, -3.7724e-03,  1.3088e-02,  ..., -1.1755e-03,\n",
       "          1.1159e-02,  5.9929e-03],\n",
       "        [-1.5273e-03, -1.1293e-02,  4.1296e-03,  ..., -3.3248e-04,\n",
       "          9.1769e-03, -3.3658e-03],\n",
       "        ...,\n",
       "        [-1.1329e-03,  4.8545e-03, -1.1407e-02,  ...,  9.5538e-03,\n",
       "          1.2967e-02,  4.3756e-03],\n",
       "        [ 5.9405e-03, -1.1547e-02, -2.3336e-03,  ...,  1.0199e-02,\n",
       "         -7.5089e-03,  9.7291e-03],\n",
       "        [ 8.3723e-04,  1.0922e-02, -1.4422e-02,  ...,  6.2752e-03,\n",
       "         -7.0702e-03, -1.3311e-02]], device='cuda:0')"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.G[-2].weight.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check on Arbitrary Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.rand((2,4))\n",
    "b = a.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2218482528576\n",
      "2219445406336\n"
     ]
    }
   ],
   "source": [
    "print(id(a))\n",
    "print(id(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4323, 0.3299, 0.1833, 0.1652],\n",
       "        [0.9400, 0.8169, 0.2842, 0.6576]])"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "a[0,:] = 9\n",
    "b\n",
    "assert torch.equal(b[:,0], torch.tensor([9.]*4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([9, 9, 9, 9])"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " torch.tensor([9]*4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([9., 9., 9., 9.])"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.equal(a, b.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0135,  0.0116, -0.0149,  ...,  0.0043,  0.0126, -0.0035],\n",
       "        [-0.0032,  0.0068,  0.0087,  ..., -0.0041, -0.0006, -0.0070],\n",
       "        [ 0.0023,  0.0073, -0.0083,  ..., -0.0140,  0.0017, -0.0065],\n",
       "        ...,\n",
       "        [ 0.0139, -0.0082,  0.0112,  ..., -0.0114, -0.0045, -0.0019],\n",
       "        [ 0.0066,  0.0042, -0.0047,  ...,  0.0103,  0.0091, -0.0073],\n",
       "        [-0.0150,  0.0064,  0.0040,  ...,  0.0056,  0.0083,  0.0140]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.D[0].weight.data.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-31-9b97fd35e612>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32massert\u001b[0m \u001b[0mnet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mG\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mnet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mD\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32massert\u001b[0m \u001b[0mnet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mG\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mnet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mD\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32massert\u001b[0m \u001b[0mnet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mG\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mnet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mD\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "assert net.G[-2] is net.D[0]\n",
    "assert net.G[-4] is net.D[2]\n",
    "assert net.G[-4] is net.D[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=100, out_features=4096, bias=True)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.G[-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=4096, out_features=100, bias=True)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.D[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "adv",
   "language": "python",
   "name": "adv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
