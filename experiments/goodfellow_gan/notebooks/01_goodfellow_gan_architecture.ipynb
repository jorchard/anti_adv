{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 01: Goodfellow GAN Architecture Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Purpose: this notebook is the workflow to creating the `GoodfellowGan()` arthictecture for the adversarial package. Note that this is done iteratively between this notebook and within the source package `adversarial/networks.py` - this notebook serves as a mental workthrough for reference and is not intended for experimental runs and may not flow linearly. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from typing import Tuple\n",
    "\n",
    "import os\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torchvision\n",
    "\n",
    "\n",
    "from adversarial.networks import (GoodfellowG,\n",
    "                                  GoodfellowD,\n",
    "                                  GoodfellowGAN)\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Globals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using DEVICE ='cpu'\n"
     ]
    }
   ],
   "source": [
    "# Directories\n",
    "EXP_DATA = os.path.abspath(os.path.join(\"..\", \"data\", \"01_raw\"))\n",
    "\n",
    "directories = [EXP_DATA]\n",
    "\n",
    "# CUDA availability    \n",
    "DEVICE = torch.device(0) if torch.cuda.is_available() else 'cpu'\n",
    "print(f\"using {DEVICE =}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in directories:\n",
    "    if not os.path.exists(p):\n",
    "        try:\n",
    "            os.makedirs(p)\n",
    "        except FileExistsError:\n",
    "            print(\"p exists and was somehow uncaught\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The torchvision MNIST dataset should be just fine. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_size = 28\n",
    "ds_train = torchvision.datasets.MNIST(EXP_DATA, train=True, download=True,\n",
    "                                transform=torchvision.transforms.Compose([\n",
    "                                torchvision.transforms.Resize((img_size,img_size)),\n",
    "                                torchvision.transforms.ToTensor(),\n",
    "                                torchvision.transforms.Lambda((lambda x: torch.flatten(x))),\n",
    "                            ]))\n",
    "ds_test = torchvision.datasets.MNIST(EXP_DATA, train=False, download=True,\n",
    "                                transform=torchvision.transforms.Compose([\n",
    "                                torchvision.transforms.Resize((img_size,img_size)),\n",
    "                                torchvision.transforms.ToTensor(),\n",
    "                                torchvision.transforms.Lambda((lambda x: torch.flatten(x))),\n",
    "                            ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = torch.utils.data.Subset(ds_train, range(1024))\n",
    "dl = torch.utils.data.DataLoader(ds, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_size = 28**2\n",
    "latent_dim = 10\n",
    "hidden_dim = 5\n",
    "device = DEVICE\n",
    "\n",
    "g_args = {\"img_size\": img_size, \n",
    "          \"latent_dim\": latent_dim,\n",
    "          \"hidden_dim\": hidden_dim,\n",
    "          \"device\": device}\n",
    "\n",
    "d_args = {\"img_size\": img_size, \n",
    "          \"latent_dim\": latent_dim,\n",
    "          \"device\": device}\n",
    "\n",
    "g = GoodfellowG(**g_args)\n",
    "d = GoodfellowD(**d_args)\n",
    "\n",
    "gf_args = {\"G\": g,\n",
    "           \"D\": d,\n",
    "           \"img_size\": img_size, \n",
    "           \"latent_dim\": latent_dim,\n",
    "           \"hidden_dim\": hidden_dim,\n",
    "           \"device\": device}\n",
    "\n",
    "gnet = GoodfellowGAN(**gf_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "code_folding": [
     1
    ]
   },
   "outputs": [],
   "source": [
    "def sample_latent_space(latent_dim: int = None, batch_size: int = 32\n",
    ") -> Tuple[torch.tensor, torch.tensor]:\n",
    "    \"\"\"Sample a normal distribution for latent space vectors\n",
    "\n",
    "    Note, that this assumes row-based data (as expected in Pytorch).\n",
    "\n",
    "    Args:\n",
    "        latent_size ): latent space vector, size: batch_size X latent_size\n",
    "\n",
    "    Returns:\n",
    "        z, u Tuple[torch.tensor]: batch_size X img_size tensor, and list of zeros as labels\n",
    "    \"\"\"\n",
    "\n",
    "    return torch.randn(batch_size, latent_dim), torch.zeros(batch_size, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 5])\n",
      "torch.Size([32, 28])\n"
     ]
    }
   ],
   "source": [
    "def test_sample_latent_space(img_size:int=None, batch_size:int=None):\n",
    "    z, u = sample_latent_space(img_size, batch_size)\n",
    "    print(z.shape)\n",
    "    assert z.shape==torch.Size([batch_size, img_size])\n",
    "    assert all([val==0.0 for val in u])\n",
    "    \n",
    "test_sample_latent_space(batch_size=3, img_size=5)\n",
    "test_sample_latent_space(batch_size=32, img_size=28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def test_generator_forward(g: GoodfellowG):\n",
    "    \n",
    "    input_dim = g.latent_dim\n",
    "    output_dim = g.img_size\n",
    "    z, u = g.sample_latent_space(input_dim, batch_size=32)\n",
    "    \n",
    "    assert z.shape == (32, input_dim)\n",
    "    \n",
    "    z = g.forward(z)\n",
    "    \n",
    "    assert z.shape == (32, output_dim)\n",
    "    \n",
    "test_generator_forward(g)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Network (sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer=torch.optim.Adam(gnet.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "made /Users/u6070354/Desktop/Brian/research/thesis/adv/anti_adv/experiments/goodfellow_gan/data/05_models\n"
     ]
    }
   ],
   "source": [
    "outpath = os.path.abspath(os.path.join(\"..\", \"data\", \"05_models\"))\n",
    "if not os.path.exists(outpath):\n",
    "    os.makedirs(outpath)\n",
    "    print(f\"made {outpath}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, d_loss: 1.835291862487793\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "-1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-164-5209139916b8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheckpoints\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m9\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Desktop/Brian/research/thesis/adv/anti_adv/src/adversarial/adversarial/networks.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, dl, optimizer, epochs, batch_size, checkpoints, path)\u001b[0m\n\u001b[1;32m    409\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlosses\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"G\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    410\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlosses\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"D\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 411\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheckpoints\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    412\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    413\u001b[0m         \u001b[0;31m# plt.figure(figsize=(4, 4))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Brian/research/thesis/adv/anti_adv/src/adversarial/adversarial/networks.py\u001b[0m in \u001b[0;36mcheckpoint\u001b[0;34m(self, epoch, checkpoints, path)\u001b[0m\n\u001b[1;32m    451\u001b[0m                 \u001b[0msave_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    452\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcheckpoints\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 453\u001b[0;31m             \u001b[0msave_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Desktop/Brian/research/thesis/adv/anti_adv/src/adversarial/adversarial/networks.py\u001b[0m in \u001b[0;36msave_checkpoint\u001b[0;34m(self, epoch, path)\u001b[0m\n\u001b[1;32m    442\u001b[0m                     \u001b[0;34m\"model_state_dict\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    443\u001b[0m                     \u001b[0;34m\"optimizer_state_dict\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 444\u001b[0;31m                     \u001b[0;34m\"loss\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlosses\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    445\u001b[0m                 },\n\u001b[1;32m    446\u001b[0m                 \u001b[0moutpath\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: -1"
     ]
    }
   ],
   "source": [
    "gnet.train(dl, optimizer=optimizer, epochs=10, checkpoints=[0,5,9], path=outpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x shape:  torch.Size([32, 784])\n",
      "t shape:  torch.Size([32])\n",
      "real logits shape:  torch.Size([32, 1])\n"
     ]
    }
   ],
   "source": [
    "dl\n",
    "x, t = next(iter(dl))\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "print(\"x shape: \", x.size())\n",
    "print(\"t shape: \", t.size())\n",
    "\n",
    "real_logits = d(x).to(torch.float32)\n",
    "t = t.to(torch.float32)\n",
    "print(\"real logits shape: \", real_logits.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-0.6450, grad_fn=<BinaryCrossEntropyBackward>)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "criterion(real_logits.view(-1, ), t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "real_logits.view(-1, ).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 1])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "real_logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=784, out_features=10, bias=True)\n",
       "  (1): LeakyReLU(negative_slope=0.01)\n",
       "  (2): Dropout(p=0.5, inplace=False)\n",
       "  (3): Linear(in_features=10, out_features=10, bias=True)\n",
       "  (4): LeakyReLU(negative_slope=0.01)\n",
       "  (5): Dropout(p=0.5, inplace=False)\n",
       "  (6): Linear(in_features=10, out_features=1, bias=True)\n",
       "  (7): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "784"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.size()[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "adv",
   "language": "python",
   "name": "adv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
